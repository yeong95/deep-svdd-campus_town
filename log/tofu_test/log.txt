2021-03-17 10:31:48,544 - root - INFO - Log file is ../log/tofu_test/log.txt.
2021-03-17 10:31:48,544 - root - INFO - Data path is ../data/두부 데이터셋.
2021-03-17 10:31:48,544 - root - INFO - Export path is ../log/tofu_test.
2021-03-17 10:31:48,544 - root - INFO - Dataset: campus
2021-03-17 10:31:48,544 - root - INFO - Normal class: 0
2021-03-17 10:31:48,545 - root - INFO - Network: campus_LeNet
2021-03-17 10:31:48,545 - root - INFO - Deep SVDD objective: one-class
2021-03-17 10:31:48,545 - root - INFO - Nu-paramerter: 0.10
2021-03-17 10:31:48,545 - root - INFO - Computation device: cpu
2021-03-17 10:31:48,545 - root - INFO - Number of dataloader workers: 0
2021-03-17 10:31:59,841 - root - INFO - Pretraining optimizer: adam
2021-03-17 10:31:59,841 - root - INFO - Pretraining learning rate: 0.0001
2021-03-17 10:31:59,841 - root - INFO - Pretraining epochs: 150
2021-03-17 10:31:59,841 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2021-03-17 10:31:59,841 - root - INFO - Pretraining batch size: 200
2021-03-17 10:31:59,841 - root - INFO - Pretraining weight decay: 0.0005
2021-03-17 10:31:59,844 - root - INFO - Starting pretraining...
2021-03-17 10:40:53,518 - root - INFO - Log file is ../log/tofu_test/log.txt.
2021-03-17 10:40:53,518 - root - INFO - Data path is ../data/두부 데이터셋.
2021-03-17 10:40:53,519 - root - INFO - Export path is ../log/tofu_test.
2021-03-17 10:40:53,519 - root - INFO - Dataset: campus
2021-03-17 10:40:53,519 - root - INFO - Normal class: 0
2021-03-17 10:40:53,519 - root - INFO - Network: campus_LeNet
2021-03-17 10:40:53,519 - root - INFO - Deep SVDD objective: one-class
2021-03-17 10:40:53,519 - root - INFO - Nu-paramerter: 0.10
2021-03-17 10:40:53,519 - root - INFO - Computation device: cpu
2021-03-17 10:40:53,519 - root - INFO - Number of dataloader workers: 0
2021-03-17 10:41:04,686 - root - INFO - Pretraining optimizer: adam
2021-03-17 10:41:04,687 - root - INFO - Pretraining learning rate: 0.0001
2021-03-17 10:41:04,687 - root - INFO - Pretraining epochs: 150
2021-03-17 10:41:04,687 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2021-03-17 10:41:04,687 - root - INFO - Pretraining batch size: 200
2021-03-17 10:41:04,687 - root - INFO - Pretraining weight decay: 0.0005
2021-03-17 10:41:04,690 - root - INFO - Starting pretraining...
2021-03-17 11:04:02,121 - root - INFO - Log file is ../log/tofu_test/log.txt.
2021-03-17 11:04:02,123 - root - INFO - Data path is ../data/두부 데이터셋.
2021-03-17 11:04:02,123 - root - INFO - Export path is ../log/tofu_test.
2021-03-17 11:04:02,123 - root - INFO - Dataset: campus
2021-03-17 11:04:02,123 - root - INFO - Normal class: 0
2021-03-17 11:04:02,123 - root - INFO - Network: campus_LeNet
2021-03-17 11:04:02,123 - root - INFO - Deep SVDD objective: one-class
2021-03-17 11:04:02,123 - root - INFO - Nu-paramerter: 0.10
2021-03-17 11:04:02,123 - root - INFO - Computation device: cpu
2021-03-17 11:04:02,123 - root - INFO - Number of dataloader workers: 0
2021-03-17 11:04:03,335 - root - INFO - Pretraining optimizer: adam
2021-03-17 11:04:03,335 - root - INFO - Pretraining learning rate: 0.0001
2021-03-17 11:04:03,335 - root - INFO - Pretraining epochs: 150
2021-03-17 11:04:03,335 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2021-03-17 11:04:03,335 - root - INFO - Pretraining batch size: 200
2021-03-17 11:04:03,335 - root - INFO - Pretraining weight decay: 0.0005
2021-03-17 11:04:03,338 - root - INFO - Starting pretraining...
2021-03-17 11:07:17,105 - root - INFO - Log file is ../log/tofu_test/log.txt.
2021-03-17 11:07:17,107 - root - INFO - Data path is ../data/두부 데이터셋.
2021-03-17 11:07:17,107 - root - INFO - Export path is ../log/tofu_test.
2021-03-17 11:07:17,107 - root - INFO - Dataset: campus
2021-03-17 11:07:17,107 - root - INFO - Normal class: 0
2021-03-17 11:07:17,107 - root - INFO - Network: campus_LeNet
2021-03-17 11:07:17,107 - root - INFO - Deep SVDD objective: one-class
2021-03-17 11:07:17,107 - root - INFO - Nu-paramerter: 0.10
2021-03-17 11:07:17,108 - root - INFO - Computation device: cpu
2021-03-17 11:07:17,108 - root - INFO - Number of dataloader workers: 0
2021-03-17 11:07:23,361 - root - INFO - Pretraining optimizer: adam
2021-03-17 11:07:23,361 - root - INFO - Pretraining learning rate: 0.0001
2021-03-17 11:07:23,361 - root - INFO - Pretraining epochs: 150
2021-03-17 11:07:23,361 - root - INFO - Pretraining learning rate scheduler milestones: (50,)
2021-03-17 11:07:23,361 - root - INFO - Pretraining batch size: 64
2021-03-17 11:07:23,361 - root - INFO - Pretraining weight decay: 0.0005
2021-03-17 11:07:23,365 - root - INFO - Starting pretraining...
2021-03-17 11:11:48,190 - root - INFO -   Epoch 1/150	 Time: 264.825	 Loss: 1118629.71093750
2021-03-17 11:16:14,737 - root - INFO -   Epoch 2/150	 Time: 266.547	 Loss: 1067268.69531250
2021-03-17 11:20:44,070 - root - INFO -   Epoch 3/150	 Time: 269.333	 Loss: 1013939.63671875
2021-03-17 11:25:09,444 - root - INFO -   Epoch 4/150	 Time: 265.374	 Loss: 957340.46875000
2021-03-17 11:29:36,783 - root - INFO -   Epoch 5/150	 Time: 267.339	 Loss: 901308.16015625
2021-03-17 11:34:07,363 - root - INFO -   Epoch 6/150	 Time: 270.580	 Loss: 846877.16015625
2021-03-17 11:38:39,015 - root - INFO -   Epoch 7/150	 Time: 271.652	 Loss: 799497.19531250
2021-03-17 11:43:07,899 - root - INFO -   Epoch 8/150	 Time: 268.884	 Loss: 759467.58203125
2021-03-17 11:47:34,647 - root - INFO -   Epoch 9/150	 Time: 266.747	 Loss: 723489.78125000
2021-03-17 11:52:02,769 - root - INFO -   Epoch 10/150	 Time: 268.121	 Loss: 693929.35156250
2021-03-17 11:56:31,713 - root - INFO -   Epoch 11/150	 Time: 268.944	 Loss: 668263.66406250
2021-03-17 12:01:00,840 - root - INFO -   Epoch 12/150	 Time: 269.127	 Loss: 648109.69140625
2021-03-17 12:05:30,176 - root - INFO -   Epoch 13/150	 Time: 269.335	 Loss: 633354.94531250
2021-03-17 12:09:59,640 - root - INFO -   Epoch 14/150	 Time: 269.464	 Loss: 620719.29687500
2021-03-17 12:14:29,460 - root - INFO -   Epoch 15/150	 Time: 269.820	 Loss: 609998.55468750
2021-03-17 12:18:59,431 - root - INFO -   Epoch 16/150	 Time: 269.971	 Loss: 600721.37500000
2021-03-17 12:23:27,104 - root - INFO -   Epoch 17/150	 Time: 267.673	 Loss: 593086.76171875
2021-03-17 12:27:56,325 - root - INFO -   Epoch 18/150	 Time: 269.220	 Loss: 586211.82812500
2021-03-17 12:32:27,876 - root - INFO -   Epoch 19/150	 Time: 271.551	 Loss: 580093.08203125
2021-03-17 12:37:00,365 - root - INFO -   Epoch 20/150	 Time: 272.488	 Loss: 573517.05859375
2021-03-17 12:41:31,726 - root - INFO -   Epoch 21/150	 Time: 271.361	 Loss: 566773.94921875
2021-03-17 12:46:01,438 - root - INFO -   Epoch 22/150	 Time: 269.712	 Loss: 561028.07031250
2021-03-17 12:50:31,186 - root - INFO -   Epoch 23/150	 Time: 269.747	 Loss: 556796.52734375
2021-03-17 12:55:02,156 - root - INFO -   Epoch 24/150	 Time: 270.969	 Loss: 552947.68359375
2021-03-17 12:59:32,086 - root - INFO -   Epoch 25/150	 Time: 269.930	 Loss: 549344.62500000
2021-03-17 13:04:01,787 - root - INFO -   Epoch 26/150	 Time: 269.700	 Loss: 546279.58593750
2021-03-17 13:08:31,769 - root - INFO -   Epoch 27/150	 Time: 269.982	 Loss: 543245.03906250
2021-03-17 13:13:01,545 - root - INFO -   Epoch 28/150	 Time: 269.775	 Loss: 540452.18359375
2021-03-17 13:17:29,850 - root - INFO -   Epoch 29/150	 Time: 268.305	 Loss: 537960.67187500
2021-03-17 13:22:01,121 - root - INFO -   Epoch 30/150	 Time: 271.270	 Loss: 535568.50390625
2021-03-17 13:26:30,200 - root - INFO -   Epoch 31/150	 Time: 269.078	 Loss: 533269.19921875
2021-03-17 13:30:59,051 - root - INFO -   Epoch 32/150	 Time: 268.851	 Loss: 531416.99609375
2021-03-17 13:35:27,258 - root - INFO -   Epoch 33/150	 Time: 268.206	 Loss: 529553.93750000
2021-03-17 13:39:58,079 - root - INFO -   Epoch 34/150	 Time: 270.821	 Loss: 527647.18750000
2021-03-17 13:44:30,232 - root - INFO -   Epoch 35/150	 Time: 272.154	 Loss: 525794.96875000
2021-03-17 13:48:59,394 - root - INFO -   Epoch 36/150	 Time: 269.161	 Loss: 523986.38476562
2021-03-17 13:53:28,207 - root - INFO -   Epoch 37/150	 Time: 268.813	 Loss: 522611.27148438
2021-03-17 13:57:56,516 - root - INFO -   Epoch 38/150	 Time: 268.308	 Loss: 521079.00976562
2021-03-17 14:02:23,745 - root - INFO -   Epoch 39/150	 Time: 267.229	 Loss: 519607.64062500
2021-03-17 14:06:52,697 - root - INFO -   Epoch 40/150	 Time: 268.952	 Loss: 518252.71484375
2021-03-17 14:11:27,505 - root - INFO -   Epoch 41/150	 Time: 274.807	 Loss: 516904.07812500
2021-03-17 14:15:56,305 - root - INFO -   Epoch 42/150	 Time: 268.800	 Loss: 515812.24609375
2021-03-17 14:20:24,371 - root - INFO -   Epoch 43/150	 Time: 268.066	 Loss: 514423.32812500
2021-03-17 14:24:53,442 - root - INFO -   Epoch 44/150	 Time: 269.071	 Loss: 513418.60742188
2021-03-17 14:29:21,482 - root - INFO -   Epoch 45/150	 Time: 268.039	 Loss: 512174.17187500
2021-03-17 14:33:50,151 - root - INFO -   Epoch 46/150	 Time: 268.669	 Loss: 510527.75585938
2021-03-17 14:38:17,659 - root - INFO -   Epoch 47/150	 Time: 267.507	 Loss: 509409.47460938
2021-03-17 14:42:44,972 - root - INFO -   Epoch 48/150	 Time: 267.313	 Loss: 508539.05468750
2021-03-17 14:47:12,223 - root - INFO -   Epoch 49/150	 Time: 267.251	 Loss: 507610.22656250
2021-03-17 14:51:39,676 - root - INFO -   Epoch 50/150	 Time: 267.453	 Loss: 506724.62695312
2021-03-17 14:51:39,676 - root - INFO -   LR scheduler: new learning rate is 1e-05
2021-03-17 14:56:06,653 - root - INFO -   Epoch 51/150	 Time: 266.976	 Loss: 506407.37109375
2021-03-17 15:00:33,426 - root - INFO -   Epoch 52/150	 Time: 266.773	 Loss: 506247.59375000
2021-03-17 15:05:01,240 - root - INFO -   Epoch 53/150	 Time: 267.813	 Loss: 506188.05273438
2021-03-17 15:09:28,831 - root - INFO -   Epoch 54/150	 Time: 267.591	 Loss: 506133.19335938
2021-03-17 15:13:56,440 - root - INFO -   Epoch 55/150	 Time: 267.609	 Loss: 506142.30078125
2021-03-17 15:18:24,996 - root - INFO -   Epoch 56/150	 Time: 268.556	 Loss: 505966.07031250
2021-03-17 15:22:53,308 - root - INFO -   Epoch 57/150	 Time: 268.312	 Loss: 506037.15234375
2021-03-17 15:27:21,967 - root - INFO -   Epoch 58/150	 Time: 268.658	 Loss: 506112.25195312
2021-03-17 15:31:50,520 - root - INFO -   Epoch 59/150	 Time: 268.553	 Loss: 505878.58789062
2021-03-17 15:36:19,474 - root - INFO -   Epoch 60/150	 Time: 268.954	 Loss: 505677.95703125
2021-03-17 15:40:46,544 - root - INFO -   Epoch 61/150	 Time: 267.070	 Loss: 505657.43359375
2021-03-17 15:45:15,474 - root - INFO -   Epoch 62/150	 Time: 268.930	 Loss: 505537.25000000
2021-03-17 15:49:46,341 - root - INFO -   Epoch 63/150	 Time: 270.866	 Loss: 505481.15820312
2021-03-17 15:54:17,745 - root - INFO -   Epoch 64/150	 Time: 271.403	 Loss: 505524.03125000
2021-03-17 15:58:46,463 - root - INFO -   Epoch 65/150	 Time: 268.718	 Loss: 505299.03320312
2021-03-17 16:03:14,910 - root - INFO -   Epoch 66/150	 Time: 268.446	 Loss: 505238.62500000
